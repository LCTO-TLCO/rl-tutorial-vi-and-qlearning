{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mdp import MDP\n",
    "import typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抽象クラス等のインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMDP(MDP):\n",
    "    def __init__(self,grid,terminals,init=(0,0),gamma=.9):\n",
    "        grid.reverse()  # because we want row 0 on bottom, not on top                                                                                                  \n",
    "        MDP.__init__(self, init, actlist=orientations,\n",
    "                     terminals=terminals, gamma=gamma)\n",
    "        self.grid = grid\n",
    "        self.rows = len(grid)\n",
    "        self.cols = len(grid[0])\n",
    "        for x in range(self.cols):\n",
    "            for y in range(self.rows):\n",
    "                self.reward[x, y] = grid[y][x]\n",
    "                if grid[y][x] is not None:\n",
    "                    self.states.add((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抽象クラスの具象化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init\n",
    "### 引数について\n",
    "- grid : 各状態での報酬(リスト？)\n",
    "- terminals : 終了状態\n",
    "- init : エージェントの初期位置\n",
    "- gamma : 割引係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def T(self, state, action):\n",
    "        if action is None:\n",
    "            return [(0.0, state)]\n",
    "        else:\n",
    "            return [(0.8, self.go(state, action)),\n",
    "                    (0.1, self.go(state, turn_right(action))),\n",
    "                    (0.1, self.go(state, turn_left(action)))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T\n",
    "    遷移モデル。状態sで行動aをとった時の次状態への遷移確率と次状態のタプル(probability, s')を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "     def go(self, state, direction):\n",
    "        state1 = vector_add(state, direction)\n",
    "        return state1 if state1 in self.states else state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## go\n",
    "    指定された方向へ移動した時の状態を返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def to_grid(self, mapping) -> list:\n",
    "        return list(reversed([[mapping.get((x, y), None)\n",
    "                               for x in range(self.cols)]\n",
    "                              for y in range(self.rows)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def to_arrows(self, policy) -> list:\n",
    "        chars = {(1, 0): '>', (0, 1): '^', (-1, 0): '<', (0, -1): 'v', None: '.'}\n",
    "        return self.to_grid({s: chars[a] for (s, a) in policy.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to_grid & to_arrows\n",
    "    表示用メソッド。listを作成している\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽象クラスで実装されている他の関数\n",
    "### actions\n",
    "    各状態で取れる行動のリストを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 価値反復法の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def value_iteration(mdp, epsilon=0.001):\n",
    "        U1 = {s: 0 for s in mdp.states}\n",
    "        R, T, gamma = mdp.R, mdp.T, mdp.gamma\n",
    "        while True:\n",
    "            U = U1.copy()\n",
    "            delta = 0\n",
    "            for s in mdp.states:\n",
    "                U1[s] = R(s) + gamma * max([sum([p * U[s1] for (p, s1) in T(s, a)])\n",
    "                                            for a in mdp.actions(s)])\n",
    "                delta = max(delta, abs(U1[s] - U[s]))\n",
    "            if delta < epsilon * (1 - gamma) / gamma:\n",
    "                return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value_iteration\n",
    "### 引数\n",
    "- mdp  \n",
    "    GridMDPのインスタンス\n",
    "- epsilon  \n",
    "    ε 微小値。なぜわざわざ与える？  \n",
    "\n",
    "### 出力\n",
    "    各状態におけるU(s)      \n",
    "\n",
    "- U(s)　　\n",
    "    価値反復法における期待利得。割引累積報酬の計算。現在の状態sから将来にわたって最優な行動を取り続けた時の期待利益。\n",
    "    \n",
    "#### 例\n",
    " ```\n",
    " >> value_iteration(sequential_decision_environment)\n",
    "{(0, 0): 0.2962883154554812,\n",
    " (0, 1): 0.3984432178350045,\n",
    " (0, 2): 0.5093943765842497,\n",
    " (1, 0): 0.25386699846479516,\n",
    " (1, 2): 0.649585681261095,\n",
    " (2, 0): 0.3447542300124158,\n",
    " (2, 1): 0.48644001739269643,\n",
    " (2, 2): 0.7953620878466678,\n",
    " (3, 0): 0.12987274656746342,\n",
    " (3, 1): -1.0,\n",
    " (3, 2): 1.0}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def best_policy(mdp, U):\n",
    "        pi = {}\n",
    "        for s in mdp.states:\n",
    "            pi[s] = argmax(mdp.actions(s), key=lambda a: expected_utility(a, s, U, mdp))\n",
    "        return pi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best_policy\n",
    "value_iteration で計算した各U(s)データから最適な政策を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def expected_utility(a, s, U, mdp):\n",
    "        return sum([p * U[s1] for (p, s1) in mdp.T(s, a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orientations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-133b3e9e1ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m0.04\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                            [-0.04, -0.04, -0.04, -0.04]],\n\u001b[0;32m----> 5\u001b[0;31m                                           terminals=[(3, 2), (3, 1)])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential_decision_environment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential_decision_environment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-18941023d420>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, grid, terminals, init, gamma)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterminals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# because we want row 0 on bottom, not on top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         MDP.__init__(self, init, actlist=orientations,\n\u001b[0m\u001b[1;32m      5\u001b[0m                      terminals=terminals, gamma=gamma)\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orientations' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sequential_decision_environment = GridMDP([[-0.04, -0.04, -0.04, +1],\n",
    "                                           [-0.04, None,  -0.04, -1],\n",
    "                                           [-0.04, -0.04, -0.04, -0.04]],\n",
    "                                          terminals=[(3, 2), (3, 1)])\n",
    "\n",
    "    pi = best_policy(sequential_decision_environment, value_iteration(sequential_decision_environment, .01))\n",
    "\n",
    "    print_table(sequential_decision_environment.to_arrows(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2018/10/03実行メモ\n",
    "    分析しつつ写して実行。  \n",
    "\n",
    "```\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "<ipython-input-19-133b3e9e1ee9> in <module>()\n",
    "      3                                            [-0.04, None,  -0.04, -1],\n",
    "      4                                            [-0.04, -0.04, -0.04, -0.04]],\n",
    "----> 5                                           terminals=[(3, 2), (3, 1)])\n",
    "      6 \n",
    "      7     pi = best_policy(sequential_decision_environment, value_iteration(sequential_decision_environment, .01))\n",
    "\n",
    "<ipython-input-11-18941023d420> in __init__(self, grid, terminals, init, gamma)\n",
    "      2     def __init__(self,grid,terminals,init=(0,0),gamma=.9):\n",
    "      3         grid.reverse()  # because we want row 0 on bottom, not on top\n",
    "----> 4         MDP.__init__(self, init, actlist=orientations,\n",
    "      5                      terminals=terminals, gamma=gamma)\n",
    "      6         self.grid = grid\n",
    "\n",
    "NameError: name 'orientations' is not defined\n",
    "\n",
    "```\n",
    "\n",
    "デフォルト引数の値が宣言されていないので、どこにあるのか探すことに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "(Qiita:Pythonではじめる強化学習)[https://qiita.com/Hironsan/items/56f6c0b2f4cfd28dd906#%E5%AE%9F%E8%B7%B5%E7%B7%A8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
